{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "1nBcATPMmndd"
      ]
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iagX34EWmojD",
        "colab_type": "code",
        "outputId": "a5bac2cc-6d0b-4c52-855d-6029409f63c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/'My Drive'/ECE_285_proj/\n",
        "%cd DeepZip_Compression"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/ECE_285_proj\n",
            "/content/drive/My Drive/ECE_285_proj/DeepZip_Compression\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FCm6wO-ms8z",
        "colab_type": "code",
        "outputId": "0128a15c-c3a3-4864-dd0d-d6aca4ff06ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arithmetic_coder.ipynb\tinput.txt\t       main.ipynb   __pycache__\n",
            "data_preparation.py\tmain-checkpoint.ipynb  my_model.h5  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x78VgVd0mndH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Bidirectional\n",
        "from keras.layers import LSTM, Flatten, Conv1D, LocallyConnected1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "from math import sqrt\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "# from matplotlib import pyplot\n",
        "import keras\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "from keras.callbacks import CSVLogger\n",
        "import keras.backend as K\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBpyl_VVmndO",
        "colab_type": "text"
      },
      "source": [
        "## DATA PREP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y2Q_SMjmndP",
        "colab_type": "code",
        "outputId": "7d7ee779-3fd1-4010-851f-53b1f823e492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "import data_preparation\n",
        "#Convert letters to integers\n",
        "integer_encoded, params = data_preparation.process_data('input.txt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15072434\n",
            "{'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
            "{0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n",
            "[[2]\n",
            " [1]\n",
            " [1]\n",
            " [3]\n",
            " [0]\n",
            " [0]\n",
            " [2]\n",
            " [1]\n",
            " [1]\n",
            " [3]]\n",
            "GCCTAAGCCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuI8s7sSmndU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs=128\n",
        "time_steps=64\n",
        "num_epochs=20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn92lIlOmndX",
        "colab_type": "code",
        "outputId": "3d7af95f-6198-42bc-9c25-1e501cf047b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#Generate traning data and its lable \n",
        "X,Y_raw, Y = data_preparation.generate_single_output_data(integer_encoded[: bs * 90 + 95 ],bs, time_steps)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11615, 1)\n",
            "(11615,)\n",
            "11520\n",
            "(11520, 65)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJoXaYJdmnda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nBcATPMmndd",
        "colab_type": "text"
      },
      "source": [
        "## Trainning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQL3Vo0Umnde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "        return 1/np.log(2) * K.categorical_crossentropy(y_true, y_pred)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVWxbczJmndg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphabet_size = Y.shape[1]\n",
        "DZ_model = Sequential()\n",
        "DZ_model.add(Embedding(alphabet_size, 32, batch_input_shape=(bs, time_steps)))\n",
        "DZ_model.add(LSTM(32, stateful=False, return_sequences=True))\n",
        "DZ_model.add(LSTM(32, stateful=False, return_sequences=True))\n",
        "DZ_model.add(Flatten())\n",
        "DZ_model.add(Dense(64, activation='relu'))\n",
        "DZ_model.add(Dense(alphabet_size, activation='softmax'))\n",
        "optim = keras.optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0, amsgrad=False)\n",
        "DZ_model.compile(loss=custom_loss, optimizer=optim)\n",
        "early_stopping = EarlyStopping(monitor='loss', mode='min', min_delta=0.005, patience=3, verbose=1)\n",
        "callbacks_list = [early_stopping]\n",
        "DZ_model.fit(X, Y, epochs=num_epochs, batch_size=bs, verbose=1, shuffle=True, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht_DJGOGmndl",
        "colab_type": "text"
      },
      "source": [
        "## Compression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ0T4Tl-mndm",
        "colab_type": "code",
        "outputId": "cb26ec43-b30b-45aa-a559-ba237a9ab427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "DZ_model = load_model('my_model.h5', compile=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAyEIB48mndp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ArithmeticEncoder(object):\n",
        "    def __init__(self, bitlen):\n",
        "        self.bit_prec = bitlen   #bit precision \n",
        "        self.max_range = 1 << self.bit_prec  #max range based on bit precision 2^bit_prec\n",
        "        self.mask = self.max_range - 1  #max range index starting at 0\n",
        "        self.renorm= self.max_range >> 1  #renormalization threshold\n",
        "        self.second_mask = self.max_range >> 1\n",
        "        self.low = 0  #initial low\n",
        "        self.high = self.mask  #initial high\n",
        "        self.s = 0  \n",
        "\n",
        "    def update(self, sym, c):\n",
        "        low = self.low   \n",
        "        high = self.high\n",
        "        range = high - low + 1\n",
        "#         print(sym)\n",
        "#         print(sym.shape )\n",
        "        sym = int(sym)\n",
        "        total = (c[-1])  #cumulative propabilities\n",
        "        symlow = (c[sym])  \n",
        "        symhigh = (c[sym+1] )\n",
        "        \n",
        "\n",
        "        newlow = low + symlow*range // total  #low in arithmetic integer\n",
        "        newhigh = low + symhigh*range // total -1 #high in arithemtic integer\n",
        "        self.low = int(newlow)\n",
        "        self.high = int(newhigh)\n",
        "        range = self.high - self.low \n",
        "#         print(\"sym:\", sym)\n",
        "#         print(\"symlow:\", self.low)\n",
        "#         print(\"symhigh:\", self.high)\n",
        "#         print(\"range:\", range)\n",
        "        \n",
        "        #renormalization\n",
        "        while((self.low ^ self.high) & self.renorm) == 0:\n",
        "            self.low = (self.low << 1) \n",
        "            range = range << 1 | 1\n",
        "            self.high = self.low + range\n",
        "            self.s = self.s + 1          \n",
        "#         print(\"renorm low:\",self.low)\n",
        "#         print(\"renorm range:\",range)\n",
        "#         print(\"renorm high:\", self.high)\n",
        "   \n",
        "    def write(self, c, sym):\n",
        "        self.update(c,sym)\n",
        "        return [self.low, self.s]\n",
        "        \n",
        "    def finish(self):\n",
        "        self.output.write(1)\n",
        "\n",
        "\n",
        "# In[25]:\n",
        "\n",
        "\n",
        "class ArithmeticDecoder(ArithmeticEncoder):\n",
        "    def __init__(self,statesize,bitin):\n",
        "        self.input = bitin\n",
        "        self.bitstream = ([int(d) for d in str(self.input)])\n",
        "        self.code = 0\n",
        "        self.max_range = 1 << statesize\n",
        "        self.renorm= self.max_range >> 1\n",
        "        self.mask = self.max_range - 1\n",
        "        self.stream = self.input[0:statesize]\n",
        "        self.low = int(self.stream,2)\n",
        "        self.t = statesize\n",
        "\n",
        "        \n",
        "    def decode(self, c):\n",
        "        self.thresh = []\n",
        "        self.total = (c[-1])\n",
        "        self.cum = c/self.total\n",
        "#         print(self.cum)\n",
        "        print(\"low:\",self.low)\n",
        "        self.thresh = [round((self.cum[i])*self.mask) for i in range(len(self.cum))]\n",
        "#         print(self.thresh)\n",
        "        for i in range(len(self.thresh)-1):\n",
        "            if((self.low < self.thresh[i+1]) & (self.low >= self.thresh[i])):\n",
        "                sym = i\n",
        "#                 print(\"encoded value:\",self.low)\n",
        "#                 print(\"threshold:\", self.thresh)\n",
        "#                 print(\"decoded value:\", sym)\n",
        "                rangenew = int(self.thresh[i+1] - self.thresh[i])\n",
        "#                 print(\"range:\", rangenew)\n",
        "#                 print(\"low:\", self.thresh[i])\n",
        "                while (rangenew < self.renorm):\n",
        "                    rangenew = rangenew << 1 \n",
        "                    self.low = self.low << 1\n",
        "                    self.thresh[i] = int(self.thresh[i]) << 1\n",
        "#                     print(\"renorm val;\",self.low)\n",
        "#                     print(\"renorm range;\",rangenew)\n",
        "                    self.thresh[i+1] = rangenew + self.thresh[i]\n",
        "#                     print(\"renorm low:\" ,self.thresh[i])\n",
        "                self.thresh = [(self.cum[j]*(self.thresh[i+1]-self.thresh[i]))+self.thresh[i] for j in range(len(self.cum))]\n",
        "                break\n",
        "        return sym"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It5W7JMRmnds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphabet_size = 4\n",
        "def cumul_d(prob):\n",
        "    return np.cumsum(prob, axis = 1)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-uH3StGmndv",
        "colab_type": "code",
        "outputId": "00f7575a-1bc6-4314-ea70-6c445fb1bc5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "bitprecision = 64\n",
        "l = int(X.shape[0] / bs) * bs \n",
        "print(l)\n",
        "print((X.shape[0])-time_steps)\n",
        "\n",
        "#Create Uniform distribution to feed in to the model\n",
        "alphabet_size = 4\n",
        "prob = np.ones(alphabet_size)/alphabet_size\n",
        "c = np.zeros(alphabet_size+1,  dtype = np.uint64)\n",
        "c[1:] = np.cumsum(prob*10000000 + 1)        \n",
        "bitstream = []\n",
        "enc = ArithmeticEncoder(bitprecision)\n",
        "\n",
        "num_iters = int((len(X)+time_steps)/bs)\n",
        "ind = np.array(range(bs))*num_iters\n",
        "prob = DZ_model.predict(X[ind,:], batch_size=bs)\n",
        "\n",
        "#Encoding\n",
        "for i in (range(bs)):\n",
        "    for j in range(min(time_steps, num_iters)):\n",
        "        new = enc.write(X[ind[i], j], c.tolist())\n",
        "        \n",
        "low_final = new[0] #final low value \n",
        "s_final = new[1]  #count of renormalizations\n",
        "ind = ind + 1\n",
        "\n",
        "#convert low to bitstream, ensure proper number of bits \n",
        "# bitstream = format(int(low_final), 'b')  \n",
        "cumul = np.zeros((bs, alphabet_size + 1), dtype = np.uint64)        \n",
        "for k in (range(num_iters - time_steps)):\n",
        "    prob = DZ_model.predict(X[ind,:], batch_size=bs)\n",
        "    cumul[:,1:] = np.cumsum(prob*10000000 + 1, axis = 1)\n",
        "#     new = enc.write(X[ind,:], cumul[i,:].tolist())\n",
        "    for i in range(bs):\n",
        "#         print(cumul[i,:].tolist())\n",
        "        enc.write(Y_raw[ind[i]], cumul[i,:].tolist())\n",
        "    ind = ind + 1\n",
        "    \n",
        "    \n",
        "low_final = new[0] #final low value \n",
        "print(\"low final:\", low_final)\n",
        "s_final = new[1]  #count of renormalizations\n",
        "ind = ind + 1\n",
        "#convert low to bitstream, ensure proper number of bits \n",
        "bitstream = format(int(low_final), 'b')  \n",
        "while len(bitstream) < (s_final+bitprecision):\n",
        "    bitstream= '0' + bitstream\n",
        "\n",
        "encval = low_final//(2**bitprecision)\n",
        "print(\"encoded value:\", encval)\n",
        "print(\"encoded bit length:\", len(bitstream))\n",
        "\n",
        "\n",
        "# else:\n",
        "#     prob = np.ones(alphabet_size)/alphabet_size\n",
        "#     cumul = np.zeros(alphabet_size+1, dtype = float)\n",
        "#     cumul[1:] = np.cumsum(prob)         \n",
        "#     print(cumul.tolist())\n",
        "#     enc = ArithmeticEncoder(bitprecision)\n",
        "#     for j in range(time_steps):\n",
        "#         new = enc.write( X[0,j], cumul.tolist())\n",
        "#     for i in (range(len(X))):\n",
        "#         prob = DZ_model.predict(X[i,:].reshape(1,-1), batch_size=1)\n",
        "#         cumul[1:] = np.cumsum(prob)\n",
        "#         new = enc.write( Y_raw[i][0], cumul)\n",
        "#     #convert low to bitstream, ensure proper number of bits \n",
        "#     bitstream = format(int(low_final), 'b')  \n",
        "#     while len(bitstream) < (s_final+bitprecision):\n",
        "#         bitstream = '0' + bitstream\n",
        "#     print(\"encoded bit length:\", len(bitstream))   \n",
        "\n",
        "# symdec = []\n",
        "# # print(\"C:\", c)\n",
        "# for symbols in range(len(X)):\n",
        "#     symdec.append(dec.decode(cumul))\n",
        "    \n",
        "    \n",
        "# print(X.shape)\n",
        "# print(\"input stream:\", X[:,0])\n",
        "# print(\"decoded num stream:\", symdec)\n",
        "# print(len(symdec))\n",
        "\n",
        "\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11520\n",
            "11456\n",
            "low final: 12948268753520993663681179206637565706996360262198296260234697665054199066220441533176602457048577997817329438227136824540629224275980658335306030504853310570037365772291974013181155592981440265743245535524119941257686879693257126134195120724855469667446489141648577616007047538438492390695415880339251706742497119779159087155419552437227845089912378518429774494947084383069935086528927802842676516542256558364549347438759376868289765962678087325261404821199531551713325780936308319592131374374394981116089413593108477668682901330999213503233410506804759920535861920826548969799815967965506581851925587933515916035393711726130541069959328357491322417026977487412032674926715982311125627958369996060090218839269753832351826120095703378999450361673472924047720166301353296517510931693487470374246583444105250808335633682031204393224962244542685170833430010947836974141393636090434098729732658974008332100223583041774448615673506388652555654238758570672799323754237742980149971314663070497400168123219412238567210171832042398780645706049422967058282581382360624269866650843405280273857681347652519015780471991416645514098894858569301497822914894710108521442594708330925280521913293720533519027103665740154341219246564179140943692273564412171597067326256839078364713776467508289989423092637101712452655222273838022460791557624699305505813172035711168241919558413687233463772088632820794885997067842335474068805223680409377980406219699109771767593897046467448982232708074630445841642389516394300712865069134135519756287800983061705216875640637239616617526114943836774980819277226263548609720796270749677921631174457090667106878383850644033043729167495835600092386029015390329803045253094490764353855713131767017246736364718239196818532466834347269038903803766546771106741080121559328960325538981807266890422885132565988252042965623773391339996703563128169859187137235778179966370679031648922208158499645538427745026943469060124833291509612769609378039004128016249721197251462802934332916489994714824522547577130503213066163518728628674568783824336664546926054434288023110781855355853148120839443872829654859644849808509983549290231543873784522115855737536268962768799443046256897544622520587666366019036554398888023452154048971446270540147337466876531423704676892834376565315980014031883749936982341930690912773095485758107458114935671799234149543743431242745479354191495183524890453410682295125222772094104414638580041715716824303992472618955675287370495304448402175382641003720259339472775722609977194493689431254609019217130734224359714853794567505553678949969830960650511706394318719216611533893448358827719239553011070850170547751707092604253118983620050146478067981759809596786663379458458492182441177407681169836494748121332751073276705944899748639502250914129767891101274493907966048086064986446430111624770509349073163703529769694259044400316826143990476130061591748978593591714906079937310114245817885924675890426314152792082249057819717674962774467590369532854120144739702490898058791338498017613158946364520056387545845291964140649795247483492655024106734347063704250810651911841854098501487539045708498241230895132789529083544566171554591956611868908001682486550430707621933696430845346405762416710791718674482176318503587544490611121808524131148240109334158766499487552385789690484326156030085427341475314988665307174474212806377190412406741374424510789448549243768357844047932380539467794279237413495238947601631225080435624107735512360618852381019836727337340660082230791655024545945628454550685815696193748327776796405974847517383580936613810499784094650481307974895169552272397961394686383913868308668535866304165789694175515946746935666163639108076890043655010485171126976374883126204019499924364592486433228422721725993948127860197641422870389762135099697632867487692792367954876834403896559080912748978137879991759204052402926720629857882560298922710100602009527860299216955504797138249943026625810783812582980554978485251800386414538818498361169698835359426703645531212643620421184401803293122444103372720599820368692376149586339883562376449693069046871533775744254873460570882636816995025117322184203392709856817804624214476335017711049277498545585117875936639713399188485450397459562577031256050653345712694453266670432722052059576341626411595305460492532436591824848596379439035092230668487906358365965219632833103871526126628920820800882156428748468787756595385386038873369029306922880047889188570907599536170366191061014853260589036170705636457921957946842297843022388292262126258779425375356158605374753277011662903768807336550295033910269135966125531567848173189012388213269019809193353722345472380297146254315889898180003892285506387441357388105047797564831353835454980286667602958238520976592245314189494015716423054039050027496406967059652181523046182646548195892197674502278632342663387489487569652417677949658152441079368154032218828513020862043535758598481759401089584921697902369674555962193296991361458342856737381416960\n",
            "encoded value: 701927055624681793515798420789564158225250671194363132989493644283112776283467534029923742098317049397853449850186907955388217296822237581708908450145212926305055834541806229612116566561382677819907372945022659978778758663200765934876697170911412060174445318305246848019190018072929206099291436529374915424301919682733288732857346674364213827169576129067167605547581504412775948050695954264696712381665778550547963982495694666593434561548282538322207116149457491514620772085387345371004274868081690349829241835190041116827771907119233287628078246547875993493942484549984280235442478735680972364839374065055518189988013700172895054853592167138510690575942546773392136611364804181551403431010599480579062699760160502876820143048128848920161379155810471707785487544199194899795611292776595801354299017073780863757729701491372311675728933973784417329590062665581165216585875096497990052221957456529966668891373383311774734951907693962153765914887419234561049519380160115425576836777102606313846848863994124746767465840553918147116903143095091103678911014297023115345955447078761192249937269697463609960281626327528330658978129048629817863674280990234930098297322079404737497059282907927364163197854395013745790017382788005946715719546455184503511773907874183446061788623301983782875934020551980167370926561132002053331843976650717716493403698148300525541641235092529201270712974374769016808556874308418848957691407752778233408188997272774494839470975884369482828508078849432936642754655271126367760819668512274255967032002141503338513435095713761286032197718445269117149361316269795357202258285109429799838606445536315614295348559955854046380861196033460092947904943613386338679215324670081891617735561930204056802827870540110491054292659758154500116128275176060122782330855451553685443339356648870756709623839457250099726254778218848122709779314885433963883822822516757526567991245616520734279796523430234913829166258997462222030752069036347954202948727296155699193296921925194240515153407703668787687177237994254009319245527411059715682137475010969418913466449061331848985646528223945148487439685836543283410573552840206460120650148417781176644357137726229986735321580974003658394157493327244233009298010903758446992994260364873070032900273240528838861829104453980469311779418342845475428539398959442726894374157148895444189605034412484640913499453183821065859295120326908414045330934473645069524759440506979118374996540458756431471401102056931077408059624378064389311224502175132822439226432737250038637254757033452375282702320245869167353800340250062050871932731039307980973368621082362894873386586376145777614653918578930795498725750826215560113499139794977498733232607833718684539975463158660402297046154087701766538657368544580350365921745723384359778413328903670995372786220844912521091165565156439247938288702244561480482659172444584341609386009610588272087565342014609404386831668570189102698452328589391119264798003231976432156087712279754810798027343535061986595993542043734760601437577929880026779894070055741182186911538350487977692769325693595948669354412063830086070240635746122663133290944766068692667440377836716974593810913879908875291845262193745794325300534794556374408355659466583884590847460680954006412903748419263950243587376445587836150773000077918698281380468925439641823080146337828675278519209216556572065917259257983979778748510138592798848704061161871530120035820897396053364857649661494852067921870342909982804527962411514254067439705588891770602441772390656655086772929699587504175962393979179261712675875319250301712559854356643118940667949852098759456525190671648234320800279596463073620123832680128729182139165901597260162559726100913362991994100255548786676351887470914508720248722874604487363080803694890742099002878374817415823297878011954706642394205375386740308616142140910257675388160460397532364597280203667167585625962895429734856819755070615665884964937318597611447920052071467843266935794431627055407200030282818248629760572382712554577668344338153037374078001888102467488145248667483881921455500995122303161754165426643877816774830406834567712239733726365764438182911208214460923772134916938566198660094149400032751249990546164909642463676031354531540050140319083165407030642120175988164411820216810831387089848451142556378588146443342999034259854884472846062532635792510953929463346372884413578565223404719889597285269880448752041399173076166783506704287684090095942689752837981435720303326678438788779184841528394329829478837770998688266173379305771353335573996689751366453328200872678982572242618926650064986264176814139799069037868691302567142906971871372102410840647546151426446441822257839498545031801105810813951078848201600147127844296909088505420572568710691243665431824618648901077559398226646802525339193177766427185126906648269791286263957292075958799123081807436336495492020727410999974729220477638441039165403786159146992077247353589993047894018718834301690443313003852816935\n",
            "encoded bit length: 16448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFodAVHSl7fA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "b28061c7-a8f6-4431-a7d8-c5c96e1c1460"
      },
      "source": [
        "\n",
        " #START DECODER\n",
        "series = np.zeros((bs,num_iters), dtype = np.uint8)  \n",
        "alphabet_size = 4\n",
        "prob = np.ones(alphabet_size)/alphabet_size\n",
        "c = np.zeros(alphabet_size+1,  dtype = np.uint64)\n",
        "c[1:] = np.cumsum(prob*10000000 + 1)        \n",
        "dec = ArithmeticDecoder(bitprecision, bitstream)\n",
        "\n",
        "num_iters = int((len(X)+time_steps)/bs)\n",
        "ind = np.array(range(bs))*num_iters\n",
        "prob = DZ_model.predict(X[ind,:], batch_size=bs)\n",
        "\n",
        "for i in (range(bs)):\n",
        "    for j in range(min(time_steps, num_iters)):\n",
        "        series[i,j] = dec.decode(c)   \n",
        "\n",
        "#convert low to bitstream, ensure proper number of bits \n",
        "# bitstream = format(int(low_final), 'b')  \n",
        "cumul = np.zeros((bs, alphabet_size + 1), dtype = np.uint64)        \n",
        "for k in (range(num_iters - time_steps)):\n",
        "    prob = DZ_model.predict(X[ind,:], batch_size=bs)\n",
        "    cumul[:,1:] = np.cumsum(prob*10000000 + 1, axis = 1)\n",
        "#     new = enc.write(X[ind,:], cumul[i,:].tolist())\n",
        "    for i in range(bs):\n",
        "#         print(cumul[i,:].tolist())\n",
        "        enc.write(Y_raw[ind[i]], cumul[i,:].tolist())\n",
        "    ind = ind + 1\n",
        "\n",
        "symdec = []\n",
        "for symbols in range(len(X)):\n",
        "    symdec.append(dec.decode(c))\n",
        "print(X.shape)\n",
        "# print(\"input stream:\", X[:,0])\n",
        "print(\"decoded num stream:\", symdec)\n",
        "print(len(symdec))\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "low: 10883353768518260489\n",
            "low: 21766707537036520978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-0d77b2930227>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#convert low to bitstream, ensure proper number of bits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-77-37f20a6f2327>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, c)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'sym' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NxuxY4Rmndz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfef3887-e8db-40c3-f085-72e7e25e9f0b"
      },
      "source": [
        " series_2d = np.zeros((bs,num_iters), dtype = np.uint8)\n",
        " print(series_2d.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 90)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9op9TcI1mnd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cumul[:,0:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZn98lYNmnd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.asscalar(cumul[-1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56XP3XHnmneB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X[i,:].reshape(1,-1).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dtk3EOMmneE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if (l > (len(X.shape[0])-timesteps)):\n",
        "    prob = model.predict(X[ind,:], batch_size=bs)\n",
        "    cumul[:,1:] = np.cumsum(prob, axis = 1)\n",
        "    for i in range(bs):\n",
        "            enc[i].write(cumul[i,:], y_original[ind[i]])\n",
        "    ind = ind + 1\n",
        "else:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhxTqspYmneI",
        "colab_type": "code",
        "outputId": "3d09c08d-fd9a-4bb9-f5fc-ef26e9df120f",
        "colab": {}
      },
      "source": [
        "DZ_model = load_model('my_model.h5', compile=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\quoca\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0QbUm_SmneS",
        "colab_type": "code",
        "outputId": "98270476-d5b8-4de8-a70a-784bb8e14d9f",
        "colab": {}
      },
      "source": [
        "#Create Uniform distribution to feed in to the model\n",
        "alphabet_size = 4\n",
        "prob = np.ones(alphabet_size)/alphabet_size\n",
        "#make an array of cumulative probabilities\n",
        "c = []\n",
        "for i in range(len(prob)+1):\n",
        "    c.append(sum(prob[0:i]))\n",
        "\n",
        "cumul = np.zeros((bs, alphabet_size+1), dtype = np.uint64)  \n",
        "for j in (range(num_iters - timesteps)):\n",
        "    prob = model.predict(X[ind,:], batch_size=bs)\n",
        "    cumul[:,1:] = np.cumsum(prob, axis = 1)\n",
        "    for i in range(bs):\n",
        "        new = enc.write(Y_raw[ind[i]], cumul[i,:].tolist())\n",
        "    ind = ind + 1\n",
        "    low_final = new[0] #fina low value \n",
        "    s_final = new[1]  #count of renormalizations\n",
        "    bitstream = format(int(low_final), 'b')  \n",
        "while len(bitstream) < (s_final+bitprecision):\n",
        "    bitstream = '0' + bitstream\n",
        "    print(\"encoded bit length:\", len(bitstream))\n",
        "\n",
        "\n",
        "    #START DECODER\n",
        "    dec = ArithmeticDecoder(bitprecision, bitstream)\n",
        "\n",
        "    symdec = []\n",
        "    for symbols in range(len(sym)):\n",
        "        symdec.append(dec.decode())\n",
        "    print(\"decoded num stream:\", symdec)\n",
        "\n",
        "    #convert numbers back to letters\n",
        "    dec_stream = []\n",
        "    for x, sym in enumerate(symdec): \n",
        "        if sym == 0:\n",
        "            dec_stream.append('a')\n",
        "        elif sym ==1:\n",
        "            dec_stream.append('c')\n",
        "        elif sym == 2:\n",
        "            dec_stream.append('g')\n",
        "        elif sym == 3:\n",
        "            dec_stream.append('t')\n",
        "\n",
        "    dec_stream = dec_stream[:-1] \n",
        "    print(\"decoded symbol stream:\", dec_stream)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'timesteps' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-85511f7a46cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcumul\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malphabet_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iters\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mcumul\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'timesteps' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG5yBoVvmneX",
        "colab_type": "code",
        "outputId": "248e8cb9-9298-4373-8329-f8a2d6abf98f",
        "colab": {}
      },
      "source": [
        "cumul"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0]], dtype=uint64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDyGTbPumneb",
        "colab_type": "code",
        "outputId": "af567d31-bdbf-4cc5-fd16-f7d33ea9d473",
        "colab": {}
      },
      "source": [
        "\n",
        "print(X)\n",
        "print(X[ind,:].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 3 3 ... 3 3 1]\n",
            " [3 3 1 ... 3 1 2]\n",
            " [3 1 2 ... 1 2 2]\n",
            " ...\n",
            " [3 0 0 ... 1 1 1]\n",
            " [0 0 3 ... 1 1 3]\n",
            " [0 3 0 ... 1 3 1]]\n",
            "(128, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyEMSoN_mnef",
        "colab_type": "code",
        "outputId": "06f5bae6-206d-4178-947d-a15f531798a2",
        "colab": {}
      },
      "source": [
        "cumul = np.zeros((bs, alphabet_size+1), dtype = np.uint64)  \n",
        "print(cumul[0,:].tolist())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI44jpHCmnej",
        "colab_type": "code",
        "outputId": "d3254263-3029-4f0d-b281-7966f0b6d8b0",
        "colab": {}
      },
      "source": [
        "print(sum(prob[1,:]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0000000596046448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCEJCyyVmnem",
        "colab_type": "code",
        "outputId": "e6a166ca-e78c-417d-da5b-e931e1d88991",
        "colab": {}
      },
      "source": [
        "import arithmetic_coder"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "symbol stream input: ['a' 'c' 'g' 't' 't' 'a' 'c' 't' 'g' 'a' 't' 'a' 'a' 't' 'a' 'c' 'c' 'g'\n",
            " 't']\n",
            "num stream: [0, 1, 2, 3, 3, 0, 1, 3, 2, 0, 3, 0, 0, 3, 0, 1, 1, 2, 3]\n",
            "probability: [0.5 0.2 0.2 0.1]\n",
            "cumulative prob: [0, 0.5, 0.7, 0.8999999999999999, 0.9999999999999999]\n",
            "encoded bit length: 106\n",
            "decoded num stream: [0, 1, 2, 3, 3, 0, 1, 3, 2, 0, 3, 0, 0, 3, 0, 1, 1, 2, 3, 1]\n",
            "decoded symbol stream: ['a', 'c', 'g', 't', 't', 'a', 'c', 't', 'g', 'a', 't', 'a', 'a', 't', 'a', 'c', 'c', 'g', 't']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLG3fhETmnep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prob = np.ones(alphabet_size)/alphabet_size\n",
        "cumul = np.zeros(alphabet_size+1, dtype = float)\n",
        "cumul[1:] = np.cumsum(prob)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTwOxFzSmnet",
        "colab_type": "code",
        "outputId": "eec89394-c910-4c29-f930-a48fd8eaeeb8",
        "colab": {}
      },
      "source": [
        "cumul"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.  , 0.25, 0.5 , 0.75, 1.  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKHyogiWmnex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prob = np.ones(alphabet_size)/alphabet_size\n",
        "cumul = np.zeros(alphabet_size+1, dtype = np.uint64)\n",
        "cumul[1:] = np.cumsum(prob*10000000 + 1)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34WIkqaqmnez",
        "colab_type": "code",
        "outputId": "2b378c9d-a247-4785-c00e-77e52ffdebfa",
        "colab": {}
      },
      "source": [
        "cumul"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([       0,  2500001,  5000002,  7500003, 10000004], dtype=uint64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmVjbzQEmne2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}