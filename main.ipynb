{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Bidirectional\n",
    "from keras.layers import LSTM, Flatten, Conv1D, LocallyConnected1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from math import sqrt\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# from matplotlib import pyplot\n",
    "import keras\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from keras.callbacks import CSVLogger\n",
    "import keras.backend as K\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15072434\n",
      "{'A': 0, 'T': 1, 'G': 2, 'C': 3}\n",
      "{0: 'A', 1: 'T', 2: 'G', 3: 'C'}\n",
      "[[2]\n",
      " [3]\n",
      " [3]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [3]\n",
      " [3]\n",
      " [1]]\n",
      "GCCTAAGCCT\n"
     ]
    }
   ],
   "source": [
    "import data_preparation\n",
    "#Convert letters to integers\n",
    "integer_encoded, params = data_preparation.process_data('input.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=128\n",
    "time_steps=64\n",
    "num_epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150722, 1)\n",
      "(150656, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Generate traning data and its lable \n",
    "X,Y = data_preparation.generate_single_output_data(integer_encoded[: 150722],bs, time_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "        return 1/np.log(2) * K.categorical_crossentropy(y_true, y_pred)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150656/150656 [==============================] - 150s 997us/step - loss: 1.8998\n",
      "Epoch 2/20\n",
      "150656/150656 [==============================] - 141s 933us/step - loss: 1.8690\n",
      "Epoch 3/20\n",
      "150656/150656 [==============================] - 139s 920us/step - loss: 1.8596\n",
      "Epoch 4/20\n",
      " 46080/150656 [========>.....................] - ETA: 1:36 - loss: 1.8457"
     ]
    }
   ],
   "source": [
    "alphabet_size = Y.shape[1]\n",
    "DZ_model = Sequential()\n",
    "DZ_model.add(Embedding(alphabet_size, 32, batch_input_shape=(bs, time_steps)))\n",
    "DZ_model.add(LSTM(32, stateful=False, return_sequences=True))\n",
    "DZ_model.add(LSTM(32, stateful=False, return_sequences=True))\n",
    "DZ_model.add(Flatten())\n",
    "DZ_model.add(Dense(64, activation='relu'))\n",
    "DZ_model.add(Dense(alphabet_size, activation='softmax'))\n",
    "optim = keras.optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0, amsgrad=False)\n",
    "DZ_model.compile(loss=custom_loss, optimizer=optim)\n",
    "early_stopping = EarlyStopping(monitor='loss', mode='min', min_delta=0.005, patience=3, verbose=1)\n",
    "callbacks_list = [early_stopping]\n",
    "DZ_model.fit(X, Y, epochs=num_epochs, batch_size=bs, verbose=1, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = int((len(X)+time_steps)/bs)\n",
    "ind = np.array(range(bs))*num_iters\n",
    "\n",
    "DZ_model = load_model('my_model.h5', compile=False)\n",
    "prob = DZ_model.predict(X[ind,:], batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 3 ... 3 3 1]\n",
      " [3 3 1 ... 3 1 0]\n",
      " [3 1 0 ... 1 0 0]\n",
      " ...\n",
      " [3 2 2 ... 1 1 1]\n",
      " [2 2 3 ... 1 1 3]\n",
      " [2 3 2 ... 1 3 1]]\n",
      "(128, 64)\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(X[ind,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000074505806\n"
     ]
    }
   ],
   "source": [
    "print(sum(prob[1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
